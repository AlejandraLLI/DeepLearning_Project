{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "image_path = '../02_Data/face_age' # Added path to gitingnore, you will have to add data to this path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path, img_size=(200, 200)):\n",
    "    X = []\n",
    "    y = []\n",
    "    for folder in os.listdir(folder_path):\n",
    "        if os.path.isdir(os.path.join(folder_path, folder)):\n",
    "            age = int(folder)\n",
    "            for file in os.listdir(os.path.join(folder_path, folder)):\n",
    "                img_path = os.path.join(folder_path, folder, file)\n",
    "                img = Image.open(img_path)\n",
    "                img = img.resize(img_size)\n",
    "                img = np.array(img)\n",
    "                X.append(img)\n",
    "                y.append(age)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "folder_path = image_path\n",
    "img_size = (200, 200)\n",
    "X, y = load_data(folder_path, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (9778, 200, 200, 3) \n",
      " - 9778: Number of images in the dataset \n",
      " - 200: Height of each image \n",
      " - 200: Width of each image \n",
      " - 3: Number of channels of each image (Red, Green, and Blue)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Shape of X: {X.shape}\", \"\\n\",\n",
    "    f\"- {X.shape[0]}: Number of images in the dataset\", \"\\n\",\n",
    "    f\"- {X.shape[1]}: Height of each image\", \"\\n\",\n",
    "    f\"- {X.shape[2]}: Width of each image\", \"\\n\",\n",
    "    f\"- {X.shape[3]}: Number of channels of each image (Red, Green, and Blue)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [  1   1   1 ... 101 110 110]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labels: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "X = X / 255.0\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of arrays: \n",
      " - X_train shape: (7822, 200, 200, 3) \n",
      " - X_test shape: (1956, 200, 200, 3) \n",
      " - y_train shape: (7822,) \n",
      " - y_test shape: (1956,)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Size of arrays:\", \"\\n\",\n",
    "    f\"- X_train shape: {X_train.shape}\", \"\\n\",\n",
    "    f\"- X_test shape: {X_test.shape}\", \"\\n\",\n",
    "    f\"- y_train shape: {y_train.shape}\", \"\\n\",\n",
    "    f\"- y_test shape: {y_test.shape}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "input_shape = (img_size[0], img_size[1], 3)\n",
    "model = create_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "245/245 [==============================] - 22s 52ms/step - loss: 1098.9629 - mae: 27.2929 - val_loss: 1288.8093 - val_mae: 29.3315\n",
      "Epoch 2/30\n",
      "245/245 [==============================] - 9s 38ms/step - loss: 541.8870 - mae: 19.4483 - val_loss: 341.6053 - val_mae: 14.1442\n",
      "Epoch 3/30\n",
      "245/245 [==============================] - 9s 38ms/step - loss: 245.5201 - mae: 12.0092 - val_loss: 179.2502 - val_mae: 9.7724\n",
      "Epoch 4/30\n",
      "245/245 [==============================] - 9s 38ms/step - loss: 177.7332 - mae: 9.9925 - val_loss: 161.2909 - val_mae: 9.6918\n",
      "Epoch 5/30\n",
      "245/245 [==============================] - 9s 38ms/step - loss: 154.7782 - mae: 9.3462 - val_loss: 96.4559 - val_mae: 6.8801\n",
      "Epoch 6/30\n",
      "245/245 [==============================] - 9s 38ms/step - loss: 142.0542 - mae: 8.9661 - val_loss: 518.7740 - val_mae: 19.1768\n",
      "Epoch 7/30\n",
      "245/245 [==============================] - 9s 38ms/step - loss: 140.6372 - mae: 8.8538 - val_loss: 114.4993 - val_mae: 7.3801\n",
      "Epoch 8/30\n",
      "245/245 [==============================] - 9s 38ms/step - loss: 127.3973 - mae: 8.5588 - val_loss: 421.4814 - val_mae: 14.4537\n",
      "Epoch 9/30\n",
      "245/245 [==============================] - 10s 39ms/step - loss: 116.7528 - mae: 8.0526 - val_loss: 80.7884 - val_mae: 6.1889\n",
      "Epoch 10/30\n",
      "245/245 [==============================] - 9s 39ms/step - loss: 122.1137 - mae: 8.2474 - val_loss: 118.0692 - val_mae: 7.5620\n",
      "Epoch 11/30\n",
      "245/245 [==============================] - 11s 43ms/step - loss: 105.8434 - mae: 7.7551 - val_loss: 95.0616 - val_mae: 7.2187\n",
      "Epoch 12/30\n",
      "245/245 [==============================] - 11s 44ms/step - loss: 104.5127 - mae: 7.6642 - val_loss: 91.6812 - val_mae: 6.5104\n",
      "Epoch 13/30\n",
      "245/245 [==============================] - 11s 45ms/step - loss: 94.4615 - mae: 7.3206 - val_loss: 86.0132 - val_mae: 6.4685\n",
      "Epoch 14/30\n",
      "245/245 [==============================] - 11s 45ms/step - loss: 94.4836 - mae: 7.2995 - val_loss: 141.6083 - val_mae: 8.3647\n",
      "Epoch 15/30\n",
      "245/245 [==============================] - 11s 45ms/step - loss: 95.8018 - mae: 7.3264 - val_loss: 106.2007 - val_mae: 6.9312\n",
      "Epoch 16/30\n",
      "245/245 [==============================] - 15s 63ms/step - loss: 86.8482 - mae: 6.9055 - val_loss: 77.5683 - val_mae: 5.9779\n",
      "Epoch 17/30\n",
      "245/245 [==============================] - 12s 47ms/step - loss: 100.1592 - mae: 7.4807 - val_loss: 116.5588 - val_mae: 7.6700\n",
      "Epoch 18/30\n",
      "245/245 [==============================] - 11s 44ms/step - loss: 103.2515 - mae: 7.5358 - val_loss: 96.2329 - val_mae: 6.8771\n",
      "Epoch 19/30\n",
      "245/245 [==============================] - 11s 45ms/step - loss: 93.7559 - mae: 7.2320 - val_loss: 101.5980 - val_mae: 6.8549\n",
      "Epoch 20/30\n",
      "245/245 [==============================] - 11s 45ms/step - loss: 86.5379 - mae: 6.9496 - val_loss: 87.6725 - val_mae: 6.3510\n",
      "Epoch 21/30\n",
      "245/245 [==============================] - 11s 45ms/step - loss: 82.1147 - mae: 6.7567 - val_loss: 97.3274 - val_mae: 6.6530\n",
      "Epoch 22/30\n",
      "245/245 [==============================] - 11s 44ms/step - loss: 81.4405 - mae: 6.7327 - val_loss: 80.4916 - val_mae: 6.1597\n",
      "Epoch 23/30\n",
      "245/245 [==============================] - 10s 39ms/step - loss: 88.7858 - mae: 7.0110 - val_loss: 75.8814 - val_mae: 5.8623\n",
      "Epoch 24/30\n",
      "245/245 [==============================] - 9s 38ms/step - loss: 78.9127 - mae: 6.6335 - val_loss: 75.1408 - val_mae: 5.9191\n",
      "Epoch 25/30\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 81.1134 - mae: 6.6636 - val_loss: 103.4296 - val_mae: 6.9695\n",
      "Epoch 26/30\n",
      "245/245 [==============================] - 10s 43ms/step - loss: 71.0571 - mae: 6.3245 - val_loss: 74.0644 - val_mae: 5.8514\n",
      "Epoch 27/30\n",
      "245/245 [==============================] - 9s 39ms/step - loss: 75.4769 - mae: 6.4556 - val_loss: 74.0540 - val_mae: 5.9491\n",
      "Epoch 28/30\n",
      "245/245 [==============================] - 11s 44ms/step - loss: 71.4834 - mae: 6.3121 - val_loss: 76.0218 - val_mae: 5.8414\n",
      "Epoch 29/30\n",
      "245/245 [==============================] - 11s 44ms/step - loss: 74.9843 - mae: 6.4502 - val_loss: 214.8265 - val_mae: 9.0635\n",
      "Epoch 30/30\n",
      "245/245 [==============================] - 11s 44ms/step - loss: 70.6641 - mae: 6.2770 - val_loss: 70.5202 - val_mae: 5.6825\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
