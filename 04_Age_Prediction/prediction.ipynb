{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 21:40:07.765890: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-12 21:40:07.821362: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-12 21:40:09.706812: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, DepthwiseConv2D\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Data Path\n",
    "face_age_path = '../02_Data/face_age' # Added path to gitingnore, you will have to add data to this path\n",
    "\n",
    "# Augmented Data Path\n",
    "augmented_data_path = '../02_Data/augmented_data' # Added path to gitingnore, you will have to add data to this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training sets\n",
    "raw_train_path = \"../02_Data/face_age_data/augmented_data_train\"\n",
    "aug_train_path = \"../02_Data/face_age_data/face_age_balanced_train\"\n",
    "\n",
    "\n",
    "# Validation set\n",
    "raw_val_path = \"../02_Data/face_age_data/face_age_balanced_val\"\n",
    "\n",
    "# Testing set\n",
    "raw_test_path = \"../02_Data/face_age_data/face_age_balanced_test\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folders, img_size=(200, 200)):\n",
    "    X = []\n",
    "    y = []\n",
    "    for folder_path in folders:\n",
    "        for folder in os.listdir(folder_path):\n",
    "            if os.path.isdir(os.path.join(folder_path, folder)):\n",
    "                age = int(folder.replace(\"aug_\", \"\"))\n",
    "                for file in os.listdir(os.path.join(folder_path, folder)):\n",
    "                    img_path = os.path.join(folder_path, folder, file)\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize(img_size)\n",
    "                    img = np.array(img)\n",
    "                    X.append(img)\n",
    "                    y.append(age)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "folder_paths = [raw_train_path, aug_train_path]\n",
    "img_size = (200, 200)\n",
    "X_train, y_train = load_data(folder_paths, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "X_train = X_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (45000, 200, 200, 3) \n",
      " - 45000: Number of images in the dataset \n",
      " - 200: Height of each image \n",
      " - 200: Width of each image \n",
      " - 3: Number of channels of each image (Red, Green, and Blue)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Shape of X: {X_train.shape}\", \"\\n\",\n",
    "    f\"- {X_train.shape[0]}: Number of images in the dataset\", \"\\n\",\n",
    "    f\"- {X_train.shape[1]}: Height of each image\", \"\\n\",\n",
    "    f\"- {X_train.shape[2]}: Width of each image\", \"\\n\",\n",
    "    f\"- {X_train.shape[3]}: Number of channels of each image (Red, Green, and Blue)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [32 32 32 ... 58 58 58]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labels: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m      2\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSize of arrays:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m- X_train shape: \u001b[39m\u001b[39m{\u001b[39;00mX_train\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m- y_train shape: \u001b[39m\u001b[39m{\u001b[39;00my_train\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Size of arrays:\", \"\\n\",\n",
    "    f\"- X_train shape: {X_train.shape}\", \"\\n\",\n",
    "    f\"- y_train shape: {y_train.shape}\", \"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train test split\n",
    "np.save(\"../02_Data/augmented_traintest_split/X_train.npy\", X_train)\n",
    "np.save(\"../02_Data/augmented_traintest_split/X_test.npy\", X_test)\n",
    "np.save(\"../02_Data/augmented_traintest_split/y_train.npy\", y_train)\n",
    "np.save(\"../02_Data/augmented_traintest_split/y_test.npy\", y_test)\n",
    "\n",
    "# # Load saved train-test split data\n",
    "# X_train = np.load(\"../02_Data/face_age_traintest_split/X_test.npy\")\n",
    "# X_test = np.load(\"../02_Data/face_age_traintest_split/X_test.npy\")\n",
    "# y_train = np.load(\"../02_Data/face_age_traintest_split/y_train.npy\")\n",
    "# y_test = np.load(\"../02_Data/face_age_traintest_split/y_test.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPUs are available\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epochs = 15\n",
    "batch_size = 32\n",
    "optimizer = \"adam\"\n",
    "loss = \"mean_squared_error\"\n",
    "metrics = ['mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 19:08:24.698664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46671 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:1a:00.0, compute capability: 8.6\n",
      "2023-05-11 19:08:24.699521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46671 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2023-05-11 19:08:24.700612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 46671 MB memory:  -> device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:88:00.0, compute capability: 8.6\n",
      "2023-05-11 19:08:24.701242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 46671 MB memory:  -> device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:89:00.0, compute capability: 8.6\n",
      "2023-05-11 19:08:24.701809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 46671 MB memory:  -> device: 4, name: NVIDIA RTX A6000, pci bus id: 0000:b1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, LeakyReLU, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, Add\n",
    "from keras.models import Model\n",
    "\n",
    "# Create a MirroredStrategy\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"GPU:0\", \"GPU:1\", \"GPU:2\", \"GPU:3\", \"GPU:4\"])\n",
    "\n",
    "# Residual block\n",
    "def residual_block(input_layer, filters):\n",
    "    x = Conv2D(filters, (3, 3), padding='same')(input_layer)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, input_layer])\n",
    "    return x\n",
    "\n",
    "def create_model(input_shape):\n",
    "    input_layer = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, 32)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    for _ in range(4):\n",
    "        x = residual_block(x, 64)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    for _ in range(6):\n",
    "        x = residual_block(x, 128)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    for _ in range(8):\n",
    "        x = residual_block(x, 256)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(512)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(256)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    output = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Open the strategy scope\n",
    "with strategy.scope():\n",
    "    input_shape = (img_size[0], img_size[1], 3)\n",
    "    model = create_model(input_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 19:10:11.278190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype int64 and shape [40169]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-05-11 19:10:11.278538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [40169,200,200,3]\n",
      "\t [[{{node Placeholder/_10}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 19:11:38.994501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-11 19:11:41.777751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-11 19:11:44.606841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-11 19:11:47.365281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-11 19:11:49.439078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-11 19:11:51.117849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-11 19:11:54.632056: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f1200b9e9d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-11 19:11:54.632098: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-05-11 19:11:54.632105: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (1): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-05-11 19:11:54.632111: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (2): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-05-11 19:11:54.632116: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (3): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-05-11 19:11:54.632121: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (4): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-05-11 19:11:54.658639: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-11 19:11:54.875458: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256/1256 [==============================] - ETA: 0s - loss: 1084.2892 - mae: 24.9366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 19:16:26.826581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype int64 and shape [10043]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-05-11 19:16:26.827005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype int64 and shape [10043]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256/1256 [==============================] - 396s 213ms/step - loss: 1084.2892 - mae: 24.9366 - val_loss: 559.2368 - val_mae: 18.4882\n",
      "Epoch 2/15\n",
      "1256/1256 [==============================] - 239s 191ms/step - loss: 358.0513 - mae: 15.0227 - val_loss: 558.6927 - val_mae: 20.0817\n",
      "Epoch 3/15\n",
      "1256/1256 [==============================] - 239s 190ms/step - loss: 319.9090 - mae: 14.1685 - val_loss: 206.0069 - val_mae: 10.8920\n",
      "Epoch 4/15\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 299.5709 - mae: 13.6775 - val_loss: 136.7419 - val_mae: 9.2706\n",
      "Epoch 5/15\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 275.7387 - mae: 13.1473 - val_loss: 298.8853 - val_mae: 14.1575\n",
      "Epoch 6/15\n",
      "1256/1256 [==============================] - 238s 189ms/step - loss: 270.7150 - mae: 13.0031 - val_loss: 289.4883 - val_mae: 13.5581\n",
      "Epoch 7/15\n",
      "1256/1256 [==============================] - 239s 190ms/step - loss: 275.0542 - mae: 13.0913 - val_loss: 274.2598 - val_mae: 13.4239\n",
      "Epoch 8/15\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 247.5370 - mae: 12.4230 - val_loss: 399.1224 - val_mae: 16.8214\n",
      "Epoch 9/15\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 239.0832 - mae: 12.2160 - val_loss: 135.1237 - val_mae: 8.9656\n",
      "Epoch 10/15\n",
      "1256/1256 [==============================] - 241s 192ms/step - loss: 225.8286 - mae: 11.8941 - val_loss: 242.8755 - val_mae: 12.6466\n",
      "Epoch 11/15\n",
      "1256/1256 [==============================] - 238s 189ms/step - loss: 219.2867 - mae: 11.7019 - val_loss: 95.6081 - val_mae: 7.7552\n",
      "Epoch 12/15\n",
      "1256/1256 [==============================] - 238s 190ms/step - loss: 213.9209 - mae: 11.6248 - val_loss: 91.1966 - val_mae: 7.7479\n",
      "Epoch 13/15\n",
      "1256/1256 [==============================] - 238s 190ms/step - loss: 203.8833 - mae: 11.3733 - val_loss: 85.8784 - val_mae: 7.3435\n",
      "Epoch 14/15\n",
      "1256/1256 [==============================] - 238s 190ms/step - loss: 201.8253 - mae: 11.2916 - val_loss: 118.8740 - val_mae: 8.7202\n",
      "Epoch 15/15\n",
      "1256/1256 [==============================] - 239s 190ms/step - loss: 213.9689 - mae: 11.5693 - val_loss: 78.3083 - val_mae: 7.0704\n"
     ]
    }
   ],
   "source": [
    "# Train the model with your data\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save, Load, and Display Model History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry with the same parameters already exists.\n",
      "Model not saved as an entry with the same parameters already exists.\n"
     ]
    }
   ],
   "source": [
    "def append_model_history_to_file(file_name, description, input_shape, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae):\n",
    "    train_mae = round(train_mae, 6)\n",
    "    validation_mae = round(validation_mae, 6)\n",
    "\n",
    "    if not os.path.exists(file_name):\n",
    "        with open(file_name, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(['Model', 'Input Shape', 'Epochs', 'Batch Size', 'Optimizer', 'Loss Function', 'Train MAE', 'Validation MAE'])\n",
    "\n",
    "    with open(file_name, 'r', newline='') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        try:\n",
    "            next(csv_reader)  # Skip the header row\n",
    "        except StopIteration:\n",
    "            pass  # The CSV file is empty or only contains the header row\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if list(map(str, row[1:])) == list(map(str, [input_shape, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae])):\n",
    "                print(\"Entry with the same parameters already exists.\")\n",
    "                return False\n",
    "\n",
    "    with open(file_name, 'a', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow([description, input_shape, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae])\n",
    "\n",
    "    return True\n",
    "\n",
    "timestamp = int(time.time())\n",
    "file_name = '../04_Age_Prediction/model_history.csv'\n",
    "description = f\"{timestamp}\"\n",
    "input_shape = str(X_train.shape[1:])\n",
    "optimizer = optimizer\n",
    "loss_function = loss\n",
    "train_mae = history.history['mae'][-1]\n",
    "validation_mae = history.history['val_mae'][-1]\n",
    "\n",
    "new_entry_added = append_model_history_to_file(file_name, description, input_shape, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae)\n",
    "\n",
    "# Save model\n",
    "def save_model_architecture(model, file_name):\n",
    "    model_json = model.to_json()\n",
    "    with open(file_name, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "if new_entry_added:\n",
    "    model_architecture_file = f\"../04_Age_Prediction/models/{description}.json\"\n",
    "    save_model_architecture(model, model_architecture_file)\n",
    "else:\n",
    "    print(\"Model not saved as an entry with the same parameters already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Input Shape</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Loss Function</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Validation MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1683270923</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>10.241365</td>\n",
       "      <td>8.678753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1683286770</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>1000</td>\n",
       "      <td>16</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>6.187893</td>\n",
       "      <td>5.758430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1683433197</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>9.656551</td>\n",
       "      <td>7.317583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1683438058</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>10.114231</td>\n",
       "      <td>7.153706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1683439878</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>8.796492</td>\n",
       "      <td>7.445862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1683441408</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>9.388038</td>\n",
       "      <td>6.963918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1683442226</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>11.328677</td>\n",
       "      <td>8.919698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1683445490</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>9.128469</td>\n",
       "      <td>6.906603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1683477636</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>650</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>8.564434</td>\n",
       "      <td>19.438639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1683835954</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>11.569266</td>\n",
       "      <td>7.070375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model    Input Shape  Epochs  Batch Size Optimizer  \\\n",
       "0  1683270923  (200, 200, 3)      10          16      adam   \n",
       "1  1683286770  (200, 200, 3)    1000          16      adam   \n",
       "2  1683433197  (200, 200, 3)      50          32      adam   \n",
       "3  1683438058  (200, 200, 3)      50          32      adam   \n",
       "4  1683439878  (200, 200, 3)      50          32      adam   \n",
       "5  1683441408  (200, 200, 3)      50          32      adam   \n",
       "6  1683442226  (200, 200, 3)      50          32      adam   \n",
       "7  1683445490  (200, 200, 3)      50          32      adam   \n",
       "8  1683477636  (200, 200, 3)     650          32      adam   \n",
       "9  1683835954  (200, 200, 3)      15          32      adam   \n",
       "\n",
       "        Loss Function  Train MAE  Validation MAE  \n",
       "0  mean_squared_error  10.241365        8.678753  \n",
       "1  mean_squared_error   6.187893        5.758430  \n",
       "2  mean_squared_error   9.656551        7.317583  \n",
       "3  mean_squared_error  10.114231        7.153706  \n",
       "4  mean_squared_error   8.796492        7.445862  \n",
       "5  mean_squared_error   9.388038        6.963918  \n",
       "6  mean_squared_error  11.328677        8.919698  \n",
       "7  mean_squared_error   9.128469        6.906603  \n",
       "8  mean_squared_error   8.564434       19.438639  \n",
       "9  mean_squared_error  11.569266        7.070375  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_to_dataframe(file_name):\n",
    "    if not os.path.exists(file_name):\n",
    "        print(\"File does not exist.\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(file_name)\n",
    "    return df\n",
    "\n",
    "file_name = '../04_Age_Prediction/model_history.csv'\n",
    "df = load_data_to_dataframe(file_name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model to load\n",
    "model_to_load = \"1683270923\"\n",
    "\n",
    "def load_and_display_model_architecture(file_name):\n",
    "    if not os.path.exists(file_name):\n",
    "        print(\"File does not exist.\")\n",
    "        return None\n",
    "\n",
    "    with open(file_name, \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "    \n",
    "    model = model_from_json(model_json)\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "model_architecture_file = f\"../04_Age_Prediction/models/{model_to_load}.json\"\n",
    "model = load_and_display_model_architecture(model_architecture_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
