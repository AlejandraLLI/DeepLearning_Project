{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 05:43:41.208748: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-11 05:43:41.259120: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 05:43:43.673348: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, DepthwiseConv2D\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Data Path\n",
    "face_age_path = '../02_Data/face_age' # Added path to gitingnore, you will have to add data to this path\n",
    "\n",
    "# Augmented Data Path\n",
    "augmented_data_path = '../02_Data/augmented_data' # Added path to gitingnore, you will have to add data to this path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folders, img_size=(200, 200)):\n",
    "    X = []\n",
    "    y = []\n",
    "    for folder_path in folders:\n",
    "        for folder in os.listdir(folder_path):\n",
    "            if os.path.isdir(os.path.join(folder_path, folder)):\n",
    "                age = int(folder.replace(\"aug_\", \"\"))\n",
    "                for file in os.listdir(os.path.join(folder_path, folder)):\n",
    "                    img_path = os.path.join(folder_path, folder, file)\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize(img_size)\n",
    "                    img = np.array(img)\n",
    "                    X.append(img)\n",
    "                    y.append(age)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "folder_paths = [face_age_path, augmented_data_path]\n",
    "img_size = (200, 200)\n",
    "X, y = load_data(folder_paths, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (50212, 200, 200, 3) \n",
      " - 50212: Number of images in the dataset \n",
      " - 200: Height of each image \n",
      " - 200: Width of each image \n",
      " - 3: Number of channels of each image (Red, Green, and Blue)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Shape of X: {X.shape}\", \"\\n\",\n",
    "    f\"- {X.shape[0]}: Number of images in the dataset\", \"\\n\",\n",
    "    f\"- {X.shape[1]}: Height of each image\", \"\\n\",\n",
    "    f\"- {X.shape[2]}: Width of each image\", \"\\n\",\n",
    "    f\"- {X.shape[3]}: Number of channels of each image (Red, Green, and Blue)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [32 32 32 ... 58 58 58]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labels: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "X = X / 255.0\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of arrays: \n",
      " - X_train shape: (40169, 200, 200, 3) \n",
      " - X_test shape: (10043, 200, 200, 3) \n",
      " - y_train shape: (40169,) \n",
      " - y_test shape: (10043,)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Size of arrays:\", \"\\n\",\n",
    "    f\"- X_train shape: {X_train.shape}\", \"\\n\",\n",
    "    f\"- X_test shape: {X_test.shape}\", \"\\n\",\n",
    "    f\"- y_train shape: {y_train.shape}\", \"\\n\",\n",
    "    f\"- y_test shape: {y_test.shape}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train test split\n",
    "np.save(\"../02_Data/augmented_traintest_split/X_train.npy\", X_train)\n",
    "np.save(\"../02_Data/augmented_traintest_split/X_test.npy\", X_test)\n",
    "np.save(\"../02_Data/augmented_traintest_split/y_train.npy\", y_train)\n",
    "np.save(\"../02_Data/augmented_traintest_split/y_test.npy\", y_test)\n",
    "\n",
    "# # Load saved train-test split data\n",
    "# X_train = np.load(\"../02_Data/face_age_traintest_split/X_test.npy\")\n",
    "# X_test = np.load(\"../02_Data/face_age_traintest_split/X_test.npy\")\n",
    "# y_train = np.load(\"../02_Data/face_age_traintest_split/y_train.npy\")\n",
    "# y_test = np.load(\"../02_Data/face_age_traintest_split/y_test.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPUs are available\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "optimizer = \"adam\"\n",
    "loss = \"mean_squared_error\"\n",
    "metrics = ['mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 05:53:12.154355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46671 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:1a:00.0, compute capability: 8.6\n",
      "2023-05-11 05:53:12.155276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46671 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2023-05-11 05:53:12.155911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 46671 MB memory:  -> device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:88:00.0, compute capability: 8.6\n",
      "2023-05-11 05:53:12.156500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 46671 MB memory:  -> device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:89:00.0, compute capability: 8.6\n",
      "2023-05-11 05:53:12.157009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 46671 MB memory:  -> device: 4, name: NVIDIA RTX A6000, pci bus id: 0000:b1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, LeakyReLU, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, Add\n",
    "from keras.models import Model\n",
    "\n",
    "# Create a MirroredStrategy\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"GPU:0\", \"GPU:1\", \"GPU:2\", \"GPU:3\", \"GPU:4\"])\n",
    "\n",
    "# Residual block\n",
    "def residual_block(input_layer, filters):\n",
    "    x = Conv2D(filters, (3, 3), padding='same')(input_layer)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, input_layer])\n",
    "    return x\n",
    "\n",
    "def create_model(input_shape):\n",
    "    input_layer = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, 32)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    for _ in range(4):\n",
    "        x = residual_block(x, 64)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    for _ in range(6):\n",
    "        x = residual_block(x, 128)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    for _ in range(8):\n",
    "        x = residual_block(x, 256)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(512)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(256)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    output = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Open the strategy scope\n",
    "with strategy.scope():\n",
    "    input_shape = (img_size[0], img_size[1], 3)\n",
    "    model = create_model(input_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 05:55:33.736047: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype int64 and shape [40169]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-05-11 05:55:33.736746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype int64 and shape [40169]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 05:57:04.292903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-11 05:57:05.673033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-11 05:57:07.915093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-11 05:57:10.497677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-11 05:57:12.762201: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-11 05:57:15.883584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-11 05:57:19.943745: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fc0789c3e40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-11 05:57:19.943828: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-05-11 05:57:19.943849: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (1): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-05-11 05:57:19.943863: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (2): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-05-11 05:57:19.943878: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (3): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-05-11 05:57:19.943891: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (4): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-05-11 05:57:20.435876: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-11 05:57:22.368320: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256/1256 [==============================] - ETA: 0s - loss: 1120.3484 - mae: 25.5260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 06:01:51.515106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype int64 and shape [10043]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-05-11 06:01:51.515421: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype int64 and shape [10043]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256/1256 [==============================] - 398s 213ms/step - loss: 1120.3484 - mae: 25.5260 - val_loss: 326.8155 - val_mae: 14.0220\n",
      "Epoch 2/50\n",
      "1256/1256 [==============================] - 243s 193ms/step - loss: 357.9591 - mae: 15.0346 - val_loss: 166.2749 - val_mae: 10.0867\n",
      "Epoch 3/50\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 312.8962 - mae: 14.0332 - val_loss: 179.4495 - val_mae: 10.4244\n",
      "Epoch 4/50\n",
      "1256/1256 [==============================] - 239s 190ms/step - loss: 291.8418 - mae: 13.5066 - val_loss: 259.3600 - val_mae: 12.1601\n",
      "Epoch 5/50\n",
      "1256/1256 [==============================] - 237s 189ms/step - loss: 274.3093 - mae: 13.0810 - val_loss: 128.5335 - val_mae: 8.9184\n",
      "Epoch 6/50\n",
      "1256/1256 [==============================] - 239s 190ms/step - loss: 252.8521 - mae: 12.5736 - val_loss: 117.0286 - val_mae: 8.5223\n",
      "Epoch 7/50\n",
      "1256/1256 [==============================] - 237s 188ms/step - loss: 245.6334 - mae: 12.3832 - val_loss: 156.3907 - val_mae: 9.6991\n",
      "Epoch 8/50\n",
      "1256/1256 [==============================] - 239s 190ms/step - loss: 244.7431 - mae: 12.3715 - val_loss: 134.2932 - val_mae: 9.1122\n",
      "Epoch 9/50\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 231.5815 - mae: 12.0247 - val_loss: 97.6365 - val_mae: 7.7502\n",
      "Epoch 10/50\n",
      "1256/1256 [==============================] - 239s 191ms/step - loss: 218.6587 - mae: 11.7074 - val_loss: 94.3799 - val_mae: 7.7766\n",
      "Epoch 11/50\n",
      "1256/1256 [==============================] - 238s 189ms/step - loss: 219.7448 - mae: 11.7534 - val_loss: 90.0378 - val_mae: 7.7328\n",
      "Epoch 12/50\n",
      "1256/1256 [==============================] - 241s 192ms/step - loss: 209.9502 - mae: 11.5014 - val_loss: 64.6578 - val_mae: 6.3630\n",
      "Epoch 13/50\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 203.6071 - mae: 11.3057 - val_loss: 69.2450 - val_mae: 6.5421\n",
      "Epoch 14/50\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 199.3669 - mae: 11.2578 - val_loss: 68.5526 - val_mae: 6.5932\n",
      "Epoch 15/50\n",
      "1256/1256 [==============================] - 238s 190ms/step - loss: 195.2552 - mae: 11.1110 - val_loss: 83.5263 - val_mae: 7.2122\n",
      "Epoch 16/50\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 191.3884 - mae: 11.0236 - val_loss: 66.3867 - val_mae: 6.5976\n",
      "Epoch 17/50\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 185.1706 - mae: 10.8267 - val_loss: 73.4950 - val_mae: 7.0135\n",
      "Epoch 18/50\n",
      "1256/1256 [==============================] - 237s 189ms/step - loss: 185.7761 - mae: 10.8761 - val_loss: 73.4216 - val_mae: 6.9335\n",
      "Epoch 19/50\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 191.3023 - mae: 10.9794 - val_loss: 72.7431 - val_mae: 7.0607\n",
      "Epoch 20/50\n",
      "1256/1256 [==============================] - 237s 189ms/step - loss: 183.6891 - mae: 10.8152 - val_loss: 68.0572 - val_mae: 6.6142\n",
      "Epoch 21/50\n",
      "1256/1256 [==============================] - 239s 190ms/step - loss: 180.8226 - mae: 10.6939 - val_loss: 86.3496 - val_mae: 7.7883\n",
      "Epoch 22/50\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 177.7466 - mae: 10.6002 - val_loss: 77.0505 - val_mae: 7.0617\n",
      "Epoch 23/50\n",
      "1256/1256 [==============================] - 238s 190ms/step - loss: 176.9665 - mae: 10.5944 - val_loss: 60.7132 - val_mae: 6.2726\n",
      "Epoch 24/50\n",
      "1256/1256 [==============================] - 240s 192ms/step - loss: 179.9854 - mae: 10.6755 - val_loss: 73.7416 - val_mae: 7.1071\n",
      "Epoch 25/50\n",
      "1256/1256 [==============================] - 237s 189ms/step - loss: 183.1133 - mae: 10.7567 - val_loss: 80.9110 - val_mae: 7.4378\n",
      "Epoch 26/50\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 179.3542 - mae: 10.6649 - val_loss: 96.6705 - val_mae: 8.2624\n",
      "Epoch 27/50\n",
      "1256/1256 [==============================] - 239s 190ms/step - loss: 174.1294 - mae: 10.5447 - val_loss: 68.2057 - val_mae: 6.7750\n",
      "Epoch 28/50\n",
      "1256/1256 [==============================] - 238s 190ms/step - loss: 181.2106 - mae: 10.7475 - val_loss: 58.1512 - val_mae: 6.2255\n",
      "Epoch 29/50\n",
      "1256/1256 [==============================] - 240s 191ms/step - loss: 170.9250 - mae: 10.4494 - val_loss: 71.3068 - val_mae: 7.0968\n",
      "Epoch 30/50\n",
      "1256/1256 [==============================] - ETA: 0s - loss: 173.9648 - mae: 10.5566"
     ]
    }
   ],
   "source": [
    "# Train the model with your data\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save, Load, and Display Model History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m         csv_writer\u001b[39m.\u001b[39mwriterow([description, input_shape, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae])\n\u001b[1;32m     26\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m timestamp \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(time\u001b[39m.\u001b[39mtime())\n\u001b[1;32m     29\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../04_Age_Prediction/model_history.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     30\u001b[0m description \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtimestamp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "def append_model_history_to_file(file_name, description, input_shape, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae):\n",
    "    train_mae = round(train_mae, 6)\n",
    "    validation_mae = round(validation_mae, 6)\n",
    "\n",
    "    if not os.path.exists(file_name):\n",
    "        with open(file_name, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(['Model', 'Input Shape', 'Epochs', 'Batch Size', 'Optimizer', 'Loss Function', 'Train MAE', 'Validation MAE'])\n",
    "\n",
    "    with open(file_name, 'r', newline='') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        try:\n",
    "            next(csv_reader)  # Skip the header row\n",
    "        except StopIteration:\n",
    "            pass  # The CSV file is empty or only contains the header row\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if list(map(str, row[1:])) == list(map(str, [input_shape, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae])):\n",
    "                print(\"Entry with the same parameters already exists.\")\n",
    "                return False\n",
    "\n",
    "    with open(file_name, 'a', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow([description, input_shape, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae])\n",
    "\n",
    "    return True\n",
    "\n",
    "timestamp = int(time.time())\n",
    "file_name = '../04_Age_Prediction/model_history.csv'\n",
    "description = f\"{timestamp}\"\n",
    "input_shape = str(X_train.shape[1:])\n",
    "optimizer = optimizer\n",
    "loss_function = loss\n",
    "train_mae = history.history['mae'][-1]\n",
    "validation_mae = history.history['val_mae'][-1]\n",
    "\n",
    "new_entry_added = append_model_history_to_file(file_name, description, input_shape, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae)\n",
    "\n",
    "# Save model\n",
    "def save_model_architecture(model, file_name):\n",
    "    model_json = model.to_json()\n",
    "    with open(file_name, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "if new_entry_added:\n",
    "    model_architecture_file = f\"../04_Age_Prediction/models/{description}.json\"\n",
    "    save_model_architecture(model, model_architecture_file)\n",
    "else:\n",
    "    print(\"Model not saved as an entry with the same parameters already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Input Shape</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Loss Function</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Validation MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1683270923</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>10.241365</td>\n",
       "      <td>8.678753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1683286770</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>1000</td>\n",
       "      <td>16</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>6.187893</td>\n",
       "      <td>5.758430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1683433197</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>9.656551</td>\n",
       "      <td>7.317583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1683438058</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>10.114231</td>\n",
       "      <td>7.153706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1683439878</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>8.796492</td>\n",
       "      <td>7.445862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1683441408</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>9.388038</td>\n",
       "      <td>6.963918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1683442226</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>11.328677</td>\n",
       "      <td>8.919698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1683445490</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>9.128469</td>\n",
       "      <td>6.906603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1683477636</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>650</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>8.564434</td>\n",
       "      <td>19.438639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model    Input Shape  Epochs  Batch Size Optimizer  \\\n",
       "0  1683270923  (200, 200, 3)      10          16      adam   \n",
       "1  1683286770  (200, 200, 3)    1000          16      adam   \n",
       "2  1683433197  (200, 200, 3)      50          32      adam   \n",
       "3  1683438058  (200, 200, 3)      50          32      adam   \n",
       "4  1683439878  (200, 200, 3)      50          32      adam   \n",
       "5  1683441408  (200, 200, 3)      50          32      adam   \n",
       "6  1683442226  (200, 200, 3)      50          32      adam   \n",
       "7  1683445490  (200, 200, 3)      50          32      adam   \n",
       "8  1683477636  (200, 200, 3)     650          32      adam   \n",
       "\n",
       "        Loss Function  Train MAE  Validation MAE  \n",
       "0  mean_squared_error  10.241365        8.678753  \n",
       "1  mean_squared_error   6.187893        5.758430  \n",
       "2  mean_squared_error   9.656551        7.317583  \n",
       "3  mean_squared_error  10.114231        7.153706  \n",
       "4  mean_squared_error   8.796492        7.445862  \n",
       "5  mean_squared_error   9.388038        6.963918  \n",
       "6  mean_squared_error  11.328677        8.919698  \n",
       "7  mean_squared_error   9.128469        6.906603  \n",
       "8  mean_squared_error   8.564434       19.438639  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_to_dataframe(file_name):\n",
    "    if not os.path.exists(file_name):\n",
    "        print(\"File does not exist.\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(file_name)\n",
    "    return df\n",
    "\n",
    "file_name = '../04_Age_Prediction/model_history.csv'\n",
    "df = load_data_to_dataframe(file_name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model to load\n",
    "model_to_load = \"1683270923\"\n",
    "\n",
    "def load_and_display_model_architecture(file_name):\n",
    "    if not os.path.exists(file_name):\n",
    "        print(\"File does not exist.\")\n",
    "        return None\n",
    "\n",
    "    with open(file_name, \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "    \n",
    "    model = model_from_json(model_json)\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "model_architecture_file = f\"../04_Age_Prediction/models/{model_to_load}.json\"\n",
    "model = load_and_display_model_architecture(model_architecture_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
