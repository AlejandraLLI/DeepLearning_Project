{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "image_path = '../02_Data/face_age' # Added path to gitingnore, you will have to add data to this path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_paths(folder_path):\n",
    "    file_paths = []\n",
    "    ages = []\n",
    "    for folder in os.listdir(folder_path):\n",
    "        if os.path.isdir(os.path.join(folder_path, folder)):\n",
    "            age = int(folder)\n",
    "            for file in os.listdir(os.path.join(folder_path, folder)):\n",
    "                file_path = os.path.join(folder_path, folder, file)\n",
    "                file_paths.append(file_path)\n",
    "                ages.append(age)\n",
    "    return file_paths, ages\n",
    "\n",
    "folder_path = image_path\n",
    "file_paths, ages = load_file_paths(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_train, file_paths_test, ages_train, ages_test = train_test_split(file_paths, ages, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def custom_data_generator(file_paths, ages, batch_size, img_size, augment=False):\n",
    "    data_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20 if augment else 0,\n",
    "        width_shift_range=0.2 if augment else 0,\n",
    "        height_shift_range=0.2 if augment else 0,\n",
    "        shear_range=0.2 if augment else 0,\n",
    "        zoom_range=0.2 if augment else 0,\n",
    "        horizontal_flip=True if augment else False,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    while True:\n",
    "        idx = np.random.permutation(len(file_paths))\n",
    "        for batch_start in range(0, len(file_paths), batch_size):\n",
    "            batch_idx = idx[batch_start:batch_start+batch_size]\n",
    "            batch_file_paths = [file_paths[i] for i in batch_idx]\n",
    "            batch_ages = [ages[i] for i in batch_idx]\n",
    "\n",
    "            batch_images = []\n",
    "            for file_path in batch_file_paths:\n",
    "                img = Image.open(file_path)\n",
    "                img = img.resize(img_size)\n",
    "                img = np.array(img)\n",
    "                batch_images.append(img)\n",
    "                \n",
    "            batch_images = np.array(batch_images)\n",
    "            batch_ages = np.array(batch_ages)\n",
    "            batch_images_augmented = data_gen.flow(batch_images, batch_ages, batch_size=batch_size, shuffle=False).next()\n",
    "            yield batch_images_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_size = (200, 200)\n",
    "train_generator = custom_data_generator(file_paths_train, ages_train, batch_size, img_size, augment=True)\n",
    "test_generator = custom_data_generator(file_paths_test, ages_test, batch_size, img_size, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "input_shape = (img_size[0], img_size[1], 3)\n",
    "model = create_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "244/244 [==============================] - 74s 284ms/step - loss: 1233.7545 - mae: 27.8761 - val_loss: 1333.6470 - val_mae: 29.4389\n",
      "Epoch 2/30\n",
      "244/244 [==============================] - 58s 239ms/step - loss: 731.2318 - mae: 21.3295 - val_loss: 1485.6138 - val_mae: 33.8352\n",
      "Epoch 3/30\n",
      "244/244 [==============================] - 58s 240ms/step - loss: 398.3294 - mae: 15.0317 - val_loss: 199.4479 - val_mae: 10.5144\n",
      "Epoch 4/30\n",
      "244/244 [==============================] - 60s 246ms/step - loss: 314.3793 - mae: 13.3964 - val_loss: 782.4519 - val_mae: 23.8049\n",
      "Epoch 5/30\n",
      "244/244 [==============================] - 66s 270ms/step - loss: 291.5349 - mae: 12.9078 - val_loss: 225.0082 - val_mae: 11.3470\n",
      "Epoch 6/30\n",
      "244/244 [==============================] - 67s 276ms/step - loss: 277.7637 - mae: 12.6512 - val_loss: 213.8882 - val_mae: 10.9707\n",
      "Epoch 7/30\n",
      "244/244 [==============================] - 66s 272ms/step - loss: 263.3974 - mae: 12.2080 - val_loss: 167.8331 - val_mae: 9.6949\n",
      "Epoch 8/30\n",
      "244/244 [==============================] - 69s 284ms/step - loss: 255.1409 - mae: 12.0137 - val_loss: 166.5611 - val_mae: 9.8987\n",
      "Epoch 9/30\n",
      "244/244 [==============================] - 66s 272ms/step - loss: 242.9268 - mae: 11.6400 - val_loss: 248.1432 - val_mae: 12.7903\n",
      "Epoch 10/30\n",
      "244/244 [==============================] - 66s 272ms/step - loss: 231.8452 - mae: 11.3972 - val_loss: 194.9821 - val_mae: 9.8970\n",
      "Epoch 11/30\n",
      "244/244 [==============================] - 68s 280ms/step - loss: 236.3336 - mae: 11.4797 - val_loss: 230.8093 - val_mae: 10.7629\n",
      "Epoch 12/30\n",
      "244/244 [==============================] - 69s 283ms/step - loss: 220.0148 - mae: 11.0181 - val_loss: 192.9781 - val_mae: 9.9670\n",
      "Epoch 13/30\n",
      "244/244 [==============================] - 70s 286ms/step - loss: 216.4785 - mae: 10.9765 - val_loss: 179.7582 - val_mae: 9.9487\n",
      "Epoch 14/30\n",
      "244/244 [==============================] - 74s 306ms/step - loss: 213.7378 - mae: 10.8353 - val_loss: 170.4307 - val_mae: 10.1039\n",
      "Epoch 15/30\n",
      "244/244 [==============================] - 71s 293ms/step - loss: 210.1918 - mae: 10.7110 - val_loss: 143.8337 - val_mae: 8.2203\n",
      "Epoch 16/30\n",
      "244/244 [==============================] - 71s 292ms/step - loss: 213.6532 - mae: 10.8097 - val_loss: 181.2749 - val_mae: 10.0402\n",
      "Epoch 17/30\n",
      "244/244 [==============================] - 80s 329ms/step - loss: 193.6071 - mae: 10.3179 - val_loss: 129.9506 - val_mae: 8.4511\n",
      "Epoch 18/30\n",
      "244/244 [==============================] - 77s 315ms/step - loss: 207.8647 - mae: 10.6656 - val_loss: 178.9791 - val_mae: 9.9486\n",
      "Epoch 19/30\n",
      "244/244 [==============================] - 62s 256ms/step - loss: 195.0666 - mae: 10.2860 - val_loss: 155.7879 - val_mae: 9.7377\n",
      "Epoch 20/30\n",
      "244/244 [==============================] - 69s 284ms/step - loss: 195.3987 - mae: 10.1816 - val_loss: 155.6588 - val_mae: 9.2984\n",
      "Epoch 21/30\n",
      "244/244 [==============================] - 76s 314ms/step - loss: 183.6523 - mae: 10.0911 - val_loss: 212.5460 - val_mae: 11.3736\n",
      "Epoch 22/30\n",
      "218/244 [=========================>....] - ETA: 7s - loss: 197.7255 - mae: 10.4500"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 14.6 MiB for an array with shape (32, 200, 200, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\nuke2\\AppData\\Local\\Temp\\ipykernel_4884\\2759120128.py\", line 31, in custom_data_generator\n    batch_images_augmented = data_gen.flow(batch_images, batch_ages, batch_size=batch_size, shuffle=False).next()\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 168, in next\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 795, in _get_batches_of_transformed_samples\n    batch_x = np.zeros(\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 14.6 MiB for an array with shape (32, 200, 200, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 14.6 MiB for an array with shape (32, 200, 200, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\nuke2\\AppData\\Local\\Temp\\ipykernel_4884\\2759120128.py\", line 31, in custom_data_generator\n    batch_images_augmented = data_gen.flow(batch_images, batch_ages, batch_size=batch_size, shuffle=False).next()\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 168, in next\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 795, in _get_batches_of_transformed_samples\n    batch_x = np.zeros(\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 14.6 MiB for an array with shape (32, 200, 200, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2004]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nuke2\\Desktop\\NW Work\\Spring Work\\DeepLearning_Project\\04_Age_Prediction\\prediction_test.ipynb Cell 11\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nuke2/Desktop/NW%20Work/Spring%20Work/DeepLearning_Project/04_Age_Prediction/prediction_test.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m validation_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(file_paths_test) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nuke2/Desktop/NW%20Work/Spring%20Work/DeepLearning_Project/04_Age_Prediction/prediction_test.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nuke2/Desktop/NW%20Work/Spring%20Work/DeepLearning_Project/04_Age_Prediction/prediction_test.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator, validation_data\u001b[39m=\u001b[39;49mtest_generator, steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch, validation_steps\u001b[39m=\u001b[39;49mvalidation_steps, epochs\u001b[39m=\u001b[39;49mepochs, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 14.6 MiB for an array with shape (32, 200, 200, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\nuke2\\AppData\\Local\\Temp\\ipykernel_4884\\2759120128.py\", line 31, in custom_data_generator\n    batch_images_augmented = data_gen.flow(batch_images, batch_ages, batch_size=batch_size, shuffle=False).next()\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 168, in next\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 795, in _get_batches_of_transformed_samples\n    batch_x = np.zeros(\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 14.6 MiB for an array with shape (32, 200, 200, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 14.6 MiB for an array with shape (32, 200, 200, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\nuke2\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\nuke2\\AppData\\Local\\Temp\\ipykernel_4884\\2759120128.py\", line 31, in custom_data_generator\n    batch_images_augmented = data_gen.flow(batch_images, batch_ages, batch_size=batch_size, shuffle=False).next()\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 168, in next\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 795, in _get_batches_of_transformed_samples\n    batch_x = np.zeros(\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 14.6 MiB for an array with shape (32, 200, 200, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2004]"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = len(file_paths_train) // batch_size\n",
    "validation_steps = len(file_paths_test) // batch_size\n",
    "epochs = 30\n",
    "\n",
    "history = model.fit(train_generator, validation_data=test_generator, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, epochs=epochs, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
