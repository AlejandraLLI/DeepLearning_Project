{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 17:45:20.213569: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-20 17:45:20.287555: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 17:45:25.635747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (Conv2D, MaxPooling2D, Flatten, \n",
    "                          Dense, Dropout, BatchNormalization, \n",
    "                          LeakyReLU, DepthwiseConv2D, MaxPooling2D,\n",
    "                          Add, Input, Activation, GlobalAveragePooling2D,\n",
    "                          Multiply, Reshape)\n",
    "\n",
    "\n",
    "from keras.utils import get_file\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import logging\n",
    "\n",
    "# Set Tensorflow log level to error \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# Set logger level to ERROR\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.ERROR)  # Set logger level to ERROR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training sets\n",
    "raw_train_path = \"../02_Data/face_age_data/face_age_balanced_train\"\n",
    "aug_train_path = \"../02_Data/face_age_data/augmented_data_train\" \n",
    "\n",
    "\n",
    "# Validation set\n",
    "raw_val_path = \"../02_Data/face_age_data/face_age_balanced_val\"\n",
    "\n",
    "# Testing set\n",
    "raw_test_path = \"../02_Data/face_age_data/face_age_balanced_test\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folders, img_size=(200, 200)):\n",
    "    X = []\n",
    "    y = []\n",
    "    for folder_path in folders:\n",
    "        for folder in os.listdir(folder_path):\n",
    "            if os.path.isdir(os.path.join(folder_path, folder)):\n",
    "                age = int(folder.replace(\"aug_\", \"\"))\n",
    "                for file in os.listdir(os.path.join(folder_path, folder)):\n",
    "                    img_path = os.path.join(folder_path, folder, file)\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize(img_size)\n",
    "                    img = np.array(img)\n",
    "                    X.append(img)\n",
    "                    y.append(age)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (200, 200)\n",
    "\n",
    "# # Load training set\n",
    "# folder_paths_train = [\n",
    "#     raw_train_path, \n",
    "#     aug_train_path\n",
    "#     ]\n",
    "# X_train, y_train = load_data(folder_paths_train, img_size)\n",
    "# X_train = X_train / 255.0  # Normalize pixel values\n",
    "\n",
    "# Load validation set\n",
    "folder_paths_val = [raw_val_path]\n",
    "X_val, y_val = load_data(folder_paths_val, img_size)\n",
    "X_val = X_val / 255.0  # Normalize pixel values\n",
    "\n",
    "# Load testing set\n",
    "folder_paths_test = [raw_test_path]\n",
    "X_test, y_test = load_data(folder_paths_test, img_size)\n",
    "X_test = X_test / 255.0  # Normalize pixel values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max pixel value in X_train after normalization: 1.0\n",
      "Min pixel value in X_train after normalization: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Load raw training set\n",
    "X_raw_train, y_raw_train = load_data([raw_train_path], img_size)\n",
    "X_raw_train = X_raw_train / 255.0  # Normalize pixel values\n",
    "\n",
    "# Load augmented training set\n",
    "X_aug_train, y_aug_train = load_data([aug_train_path], img_size)\n",
    "X_aug_train = X_aug_train / 255.0  # Normalize pixel values\n",
    "\n",
    "# Concatenate raw and augmented training set\n",
    "X_train = np.concatenate((X_raw_train, X_aug_train), axis=0)\n",
    "y_train = np.concatenate((y_raw_train, y_aug_train), axis=0)\n",
    "\n",
    "# Now check the maximum and minimum pixel values in X_train\n",
    "print(\"Max pixel value in X_train after normalization:\", np.max(X_train))\n",
    "print(\"Min pixel value in X_train after normalization:\", np.min(X_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (45000, 200, 200, 3) \n",
      " - 45000: Number of images in the dataset \n",
      " - 200: Height of each image \n",
      " - 200: Width of each image \n",
      " - 3: Number of channels of each image (Red, Green, and Blue)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Shape of X: {X_train.shape}\", \"\\n\",\n",
    "    f\"- {X_train.shape[0]}: Number of images in the dataset\", \"\\n\",\n",
    "    f\"- {X_train.shape[1]}: Height of each image\", \"\\n\",\n",
    "    f\"- {X_train.shape[2]}: Width of each image\", \"\\n\",\n",
    "    f\"- {X_train.shape[3]}: Number of channels of each image (Red, Green, and Blue)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [32 32 32 ... 58 58 58]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labels: {y_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of arrays: \n",
      " - X_train shape: (45000, 200, 200, 3) \n",
      " - y_train shape: (45000,) \n",
      " - X_val shape: (1400, 200, 200, 3) \n",
      " - y_val shape: (1400,) \n",
      " - X_test shape: (1750, 200, 200, 3) \n",
      " - y_test shape: (1750,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Size of arrays:\", \"\\n\",\n",
    "    f\"- X_train shape: {X_train.shape}\", \"\\n\",\n",
    "    f\"- y_train shape: {y_train.shape}\", \"\\n\",\n",
    "    f\"- X_val shape: {X_val.shape}\", \"\\n\",\n",
    "    f\"- y_val shape: {y_val.shape}\", \"\\n\",\n",
    "    f\"- X_test shape: {X_test.shape}\", \"\\n\",\n",
    "    f\"- y_test shape: {y_test.shape}\", \"\\n\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  5\n",
      "Using GPUs:  ['/physical_device:GPU:0', '/physical_device:GPU:1', '/physical_device:GPU:2', '/physical_device:GPU:3', '/physical_device:GPU:4']\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4']\n"
     ]
    }
   ],
   "source": [
    "def set_gpus(*gpu_indices):\n",
    "    # Get list of GPUs\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    print(\"Num GPUs Available: \", len(gpus))\n",
    "\n",
    "    if gpus:\n",
    "        visible_gpus = [gpus[i] for i in gpu_indices]\n",
    "        try:\n",
    "            # Only use specified GPUs and ignore the others\n",
    "            tf.config.experimental.set_visible_devices(visible_gpus, 'GPU')\n",
    "            for gpu in visible_gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"Using GPUs: \", [gpu.name for gpu in visible_gpus])\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    return visible_gpus\n",
    "\n",
    "# Call the function with the indices of the GPUs you want to use\n",
    "visible_gpus = set_gpus(0, 1, 2, 3, 4)  # Use the second, third, fourth, and fifth GPU\n",
    "\n",
    "# Extract names of the GPUs being used\n",
    "gpu_names = ['/device:GPU:' + gpu.name.split(':')[-1] for gpu in visible_gpus]\n",
    "print(gpu_names)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "optimizer = \"adam\"\n",
    "loss = \"mean_squared_error\"\n",
    "metrics = ['mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 17:52:41.818401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46671 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:1a:00.0, compute capability: 8.6\n",
      "2023-05-20 17:52:41.819329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46671 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2023-05-20 17:52:41.819906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 46671 MB memory:  -> device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:88:00.0, compute capability: 8.6\n",
      "2023-05-20 17:52:41.820518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 46671 MB memory:  -> device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:89:00.0, compute capability: 8.6\n",
      "2023-05-20 17:52:41.821090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 46671 MB memory:  -> device: 4, name: NVIDIA RTX A6000, pci bus id: 0000:b1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "# Create a MirroredStrategy\n",
    "strategy = tf.distribute.MirroredStrategy(devices=gpu_names)\n",
    "\n",
    "# 18 (Current)\n",
    "# .h5\n",
    "# Augmented + Raw data\n",
    "\n",
    "# Residual block\n",
    "def residual_block(input_layer, filters):\n",
    "    x = Conv2D(filters, (3, 3), padding='same')(input_layer)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    input_layer = Conv2D(filters, (1, 1), padding='same')(input_layer)\n",
    "    \n",
    "    x = Add()([x, input_layer])\n",
    "    return x\n",
    "\n",
    "def create_model(input_shape):\n",
    "    input_layer = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = residual_block(x, 32)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = residual_block(x, 64)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = residual_block(x, 128)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = residual_block(x, 256)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(512)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(256)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    output = Dense(1)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Open the strategy scope\n",
    "with strategy.scope():\n",
    "    input_shape = (img_size[0], img_size[1], 3)\n",
    "    model = create_model(input_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback to save the model's weights\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"../04_Age_Prediction/08_models/best_model.h5\", save_best_only=True)\n",
    "\n",
    "# Create a callback that stops the training if there is no improvement in the validation loss for 15 consecutive epochs\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 18:03:18.854053: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 20.12GiB (rounded to 21600000000)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-05-20 18:03:18.854113: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-05-20 18:03:18.854129: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 123, Chunks in use: 114. 30.8KiB allocated for chunks. 28.5KiB in use in bin. 6.3KiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854138: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 30, Chunks in use: 25. 16.2KiB allocated for chunks. 13.2KiB in use in bin. 13.2KiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854146: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 29, Chunks in use: 27. 29.2KiB allocated for chunks. 27.2KiB in use in bin. 27.0KiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854176: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 17, Chunks in use: 15. 34.8KiB allocated for chunks. 30.8KiB in use in bin. 30.8KiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854184: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 3, Chunks in use: 3. 13.5KiB allocated for chunks. 13.5KiB in use in bin. 13.5KiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854191: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 1, Chunks in use: 1. 13.8KiB allocated for chunks. 13.8KiB in use in bin. 13.7KiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854199: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854207: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 3, Chunks in use: 3. 96.0KiB allocated for chunks. 96.0KiB in use in bin. 96.0KiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854213: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854221: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 3, Chunks in use: 3. 448.0KiB allocated for chunks. 448.0KiB in use in bin. 384.0KiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854229: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 1, Chunks in use: 1. 351.8KiB allocated for chunks. 351.8KiB in use in bin. 351.6KiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854236: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 3, Chunks in use: 3. 1.54MiB allocated for chunks. 1.54MiB in use in bin. 1.50MiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854241: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854248: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 3, Chunks in use: 1. 9.60MiB allocated for chunks. 3.20MiB in use in bin. 3.20MiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854254: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854260: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854265: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854271: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854277: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854284: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 2, Chunks in use: 0. 388.85MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854291: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 7, Chunks in use: 5. 33.61GiB allocated for chunks. 21.81GiB in use in bin. 21.81GiB client-requested in use in bin.\n",
      "2023-05-20 18:03:18.854298: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 20.12GiB was 256.00MiB, Chunk State: \n",
      "2023-05-20 18:03:18.854319: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 711.50MiB | Requested Size: 312.50MiB | in_use: 0 | bin_num: 20, prev:   Size: 312.50MiB | Requested Size: 312.50MiB | in_use: 1 | bin_num: -1\n",
      "2023-05-20 18:03:18.854328: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 11.10GiB | Requested Size: 313.18MiB | in_use: 0 | bin_num: 20, prev:   Size: 801.09MiB | Requested Size: 801.09MiB | in_use: 1 | bin_num: -1\n",
      "2023-05-20 18:03:18.854332: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 34359738368\n",
      "2023-05-20 18:03:18.854341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ed450000000 of size 21600000000 next 85\n",
      "2023-05-20 18:03:18.854347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ed95775d800 of size 840000000 next 188\n",
      "2023-05-20 18:03:18.854351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7ed989873a00 of size 11919738368 next 18446744073709551615\n",
      "2023-05-20 18:03:18.854356: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 1073741824\n",
      "2023-05-20 18:03:18.854361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ee9d8000000 of size 327680000 next 66\n",
      "2023-05-20 18:03:18.854366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7ee9eb880000 of size 746061824 next 18446744073709551615\n",
      "2023-05-20 18:03:18.854370: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 536870912\n",
      "2023-05-20 18:03:18.854375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea18000000 of size 327680000 next 137\n",
      "2023-05-20 18:03:18.854380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b880000 of size 524288 next 145\n",
      "2023-05-20 18:03:18.854384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b900000 of size 1024 next 146\n",
      "2023-05-20 18:03:18.854389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b900400 of size 1024 next 147\n",
      "2023-05-20 18:03:18.854393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b900800 of size 1024 next 148\n",
      "2023-05-20 18:03:18.854397: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b900c00 of size 1024 next 149\n",
      "2023-05-20 18:03:18.854402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b901000 of size 1024 next 150\n",
      "2023-05-20 18:03:18.854406: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b901400 of size 1024 next 151\n",
      "2023-05-20 18:03:18.854410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b901800 of size 1024 next 152\n",
      "2023-05-20 18:03:18.854415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b901c00 of size 1024 next 153\n",
      "2023-05-20 18:03:18.854419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b902000 of size 256 next 154\n",
      "2023-05-20 18:03:18.854424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b902100 of size 256 next 155\n",
      "2023-05-20 18:03:18.854428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2b902200 of size 256 next 156\n",
      "2023-05-20 18:03:18.854432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b902300 of size 256 next 157\n",
      "2023-05-20 18:03:18.854437: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b902400 of size 256 next 158\n",
      "2023-05-20 18:03:18.854441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b902500 of size 256 next 159\n",
      "2023-05-20 18:03:18.854445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b902600 of size 256 next 160\n",
      "2023-05-20 18:03:18.854450: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b902700 of size 256 next 161\n",
      "2023-05-20 18:03:18.854455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b902800 of size 2048 next 162\n",
      "2023-05-20 18:03:18.854459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903000 of size 256 next 163\n",
      "2023-05-20 18:03:18.854463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903100 of size 1024 next 164\n",
      "2023-05-20 18:03:18.854470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903500 of size 256 next 165\n",
      "2023-05-20 18:03:18.854474: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903600 of size 256 next 166\n",
      "2023-05-20 18:03:18.854478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903700 of size 256 next 167\n",
      "2023-05-20 18:03:18.854483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903800 of size 256 next 168\n",
      "2023-05-20 18:03:18.854487: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903900 of size 256 next 169\n",
      "2023-05-20 18:03:18.854492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903a00 of size 256 next 170\n",
      "2023-05-20 18:03:18.854496: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903b00 of size 256 next 171\n",
      "2023-05-20 18:03:18.854500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903c00 of size 256 next 172\n",
      "2023-05-20 18:03:18.854505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903d00 of size 256 next 173\n",
      "2023-05-20 18:03:18.854509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903e00 of size 256 next 174\n",
      "2023-05-20 18:03:18.854513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b903f00 of size 256 next 175\n",
      "2023-05-20 18:03:18.854518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904000 of size 256 next 176\n",
      "2023-05-20 18:03:18.854522: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904100 of size 256 next 177\n",
      "2023-05-20 18:03:18.854526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904200 of size 256 next 178\n",
      "2023-05-20 18:03:18.854531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904300 of size 256 next 179\n",
      "2023-05-20 18:03:18.854535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904400 of size 256 next 180\n",
      "2023-05-20 18:03:18.854540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904500 of size 256 next 181\n",
      "2023-05-20 18:03:18.854544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904600 of size 256 next 182\n",
      "2023-05-20 18:03:18.854548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904700 of size 256 next 183\n",
      "2023-05-20 18:03:18.854553: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904800 of size 256 next 184\n",
      "2023-05-20 18:03:18.854557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904900 of size 256 next 185\n",
      "2023-05-20 18:03:18.854561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904a00 of size 256 next 231\n",
      "2023-05-20 18:03:18.854566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904b00 of size 256 next 200\n",
      "2023-05-20 18:03:18.854570: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904c00 of size 256 next 250\n",
      "2023-05-20 18:03:18.854574: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2b904d00 of size 256 next 213\n",
      "2023-05-20 18:03:18.854579: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b904e00 of size 256 next 273\n",
      "2023-05-20 18:03:18.854583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2b904f00 of size 768 next 253\n",
      "2023-05-20 18:03:18.854588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b905200 of size 256 next 218\n",
      "2023-05-20 18:03:18.854592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2b905300 of size 1024 next 207\n",
      "2023-05-20 18:03:18.854596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b905700 of size 256 next 216\n",
      "2023-05-20 18:03:18.854601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b905800 of size 256 next 194\n",
      "2023-05-20 18:03:18.854605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b905900 of size 256 next 244\n",
      "2023-05-20 18:03:18.854610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2b905a00 of size 512 next 247\n",
      "2023-05-20 18:03:18.854615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b905c00 of size 256 next 238\n",
      "2023-05-20 18:03:18.854620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2b905d00 of size 256 next 272\n",
      "2023-05-20 18:03:18.854624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b905e00 of size 256 next 55\n",
      "2023-05-20 18:03:18.854629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2b905f00 of size 256 next 225\n",
      "2023-05-20 18:03:18.854633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b906000 of size 256 next 27\n",
      "2023-05-20 18:03:18.854637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b906100 of size 256 next 243\n",
      "2023-05-20 18:03:18.854642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b906200 of size 512 next 274\n",
      "2023-05-20 18:03:18.854649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b906400 of size 512 next 239\n",
      "2023-05-20 18:03:18.854653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2b906600 of size 2048 next 222\n",
      "2023-05-20 18:03:18.854658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b906e00 of size 512 next 235\n",
      "2023-05-20 18:03:18.854662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b907000 of size 512 next 259\n",
      "2023-05-20 18:03:18.854666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2b907200 of size 2048 next 268\n",
      "2023-05-20 18:03:18.854671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b907a00 of size 256 next 195\n",
      "2023-05-20 18:03:18.854675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2b907b00 of size 768 next 199\n",
      "2023-05-20 18:03:18.854680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b907e00 of size 1024 next 187\n",
      "2023-05-20 18:03:18.854684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2b908200 of size 1024 next 242\n",
      "2023-05-20 18:03:18.854689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2b908600 of size 3345408 next 189\n",
      "2023-05-20 18:03:18.854693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2bc39200 of size 256 next 190\n",
      "2023-05-20 18:03:18.854697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2bc39300 of size 3360000 next 204\n",
      "2023-05-20 18:03:18.854701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2bf6d800 of size 14080 next 233\n",
      "2023-05-20 18:03:18.854706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea2bf70f00 of size 3360000 next 234\n",
      "2023-05-20 18:03:18.854711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea2c2a5400 of size 198552576 next 18446744073709551615\n",
      "2023-05-20 18:03:18.854715: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 536870912\n",
      "2023-05-20 18:03:18.854720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea38000000 of size 327680000 next 138\n",
      "2023-05-20 18:03:18.854725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea4b880000 of size 209190912 next 18446744073709551615\n",
      "2023-05-20 18:03:18.854729: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 2097152\n",
      "2023-05-20 18:03:18.854733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e000000 of size 256 next 1\n",
      "2023-05-20 18:03:18.854738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e000100 of size 1280 next 2\n",
      "2023-05-20 18:03:18.854743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e000600 of size 256 next 3\n",
      "2023-05-20 18:03:18.854747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e000700 of size 256 next 4\n",
      "2023-05-20 18:03:18.854751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e000800 of size 256 next 5\n",
      "2023-05-20 18:03:18.854756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e000900 of size 256 next 7\n",
      "2023-05-20 18:03:18.854760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e000a00 of size 256 next 6\n",
      "2023-05-20 18:03:18.854766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e000b00 of size 256 next 8\n",
      "2023-05-20 18:03:18.854770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e000c00 of size 256 next 9\n",
      "2023-05-20 18:03:18.854775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e000d00 of size 256 next 10\n",
      "2023-05-20 18:03:18.854779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e000e00 of size 256 next 11\n",
      "2023-05-20 18:03:18.854783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea5e000f00 of size 512 next 13\n",
      "2023-05-20 18:03:18.854788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001100 of size 256 next 14\n",
      "2023-05-20 18:03:18.854792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001200 of size 256 next 15\n",
      "2023-05-20 18:03:18.854797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001300 of size 256 next 17\n",
      "2023-05-20 18:03:18.854801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001400 of size 256 next 18\n",
      "2023-05-20 18:03:18.854805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001500 of size 256 next 16\n",
      "2023-05-20 18:03:18.854810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea5e001600 of size 256 next 198\n",
      "2023-05-20 18:03:18.854814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001700 of size 256 next 22\n",
      "2023-05-20 18:03:18.854818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001800 of size 256 next 23\n",
      "2023-05-20 18:03:18.854823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001900 of size 256 next 24\n",
      "2023-05-20 18:03:18.854827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001a00 of size 256 next 26\n",
      "2023-05-20 18:03:18.854831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001b00 of size 256 next 20\n",
      "2023-05-20 18:03:18.854836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001c00 of size 768 next 21\n",
      "2023-05-20 18:03:18.854840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e001f00 of size 256 next 25\n",
      "2023-05-20 18:03:18.854845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea5e002000 of size 256 next 262\n",
      "2023-05-20 18:03:18.854849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e002100 of size 256 next 30\n",
      "2023-05-20 18:03:18.854854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e002200 of size 256 next 31\n",
      "2023-05-20 18:03:18.854858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e002300 of size 256 next 32\n",
      "2023-05-20 18:03:18.854862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e002400 of size 512 next 35\n",
      "2023-05-20 18:03:18.854867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e002600 of size 512 next 33\n",
      "2023-05-20 18:03:18.854871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e002800 of size 512 next 34\n",
      "2023-05-20 18:03:18.854875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea5e002a00 of size 1024 next 39\n",
      "2023-05-20 18:03:18.854880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e002e00 of size 256 next 40\n",
      "2023-05-20 18:03:18.854884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e002f00 of size 256 next 41\n",
      "2023-05-20 18:03:18.854889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e003000 of size 512 next 28\n",
      "2023-05-20 18:03:18.854893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e003200 of size 2304 next 29\n",
      "2023-05-20 18:03:18.854897: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e003b00 of size 512 next 43\n",
      "2023-05-20 18:03:18.854902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e003d00 of size 512 next 42\n",
      "2023-05-20 18:03:18.854906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e003f00 of size 256 next 196\n",
      "2023-05-20 18:03:18.854911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e004000 of size 256 next 264\n",
      "2023-05-20 18:03:18.854916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea5e004100 of size 256 next 249\n",
      "2023-05-20 18:03:18.854921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e004200 of size 256 next 47\n",
      "2023-05-20 18:03:18.854925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e004300 of size 256 next 48\n",
      "2023-05-20 18:03:18.854929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e004400 of size 256 next 49\n",
      "2023-05-20 18:03:18.854934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e004500 of size 1024 next 52\n",
      "2023-05-20 18:03:18.854938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e004900 of size 1024 next 50\n",
      "2023-05-20 18:03:18.854942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e004d00 of size 1024 next 51\n",
      "2023-05-20 18:03:18.854947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea5e005100 of size 256 next 252\n",
      "2023-05-20 18:03:18.854951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e005200 of size 256 next 248\n",
      "2023-05-20 18:03:18.854956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea5e005300 of size 256 next 193\n",
      "2023-05-20 18:03:18.854960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e005400 of size 256 next 241\n",
      "2023-05-20 18:03:18.854964: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e005500 of size 256 next 265\n",
      "2023-05-20 18:03:18.854968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e005600 of size 256 next 271\n",
      "2023-05-20 18:03:18.854973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7eea5e005700 of size 512 next 56\n",
      "2023-05-20 18:03:18.854977: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e005900 of size 256 next 57\n",
      "2023-05-20 18:03:18.854982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e005a00 of size 256 next 58\n",
      "2023-05-20 18:03:18.854986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e005b00 of size 256 next 68\n",
      "2023-05-20 18:03:18.854991: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e005c00 of size 256 next 69\n",
      "2023-05-20 18:03:18.854995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e005d00 of size 256 next 76\n",
      "2023-05-20 18:03:18.854999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e005e00 of size 256 next 77\n",
      "2023-05-20 18:03:18.855003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e005f00 of size 256 next 45\n",
      "2023-05-20 18:03:18.855008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e006000 of size 4608 next 46\n",
      "2023-05-20 18:03:18.855013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e007200 of size 2048 next 62\n",
      "2023-05-20 18:03:18.855017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e007a00 of size 2048 next 59\n",
      "2023-05-20 18:03:18.855021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e008200 of size 2048 next 60\n",
      "2023-05-20 18:03:18.855026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e008a00 of size 2048 next 65\n",
      "2023-05-20 18:03:18.855030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e009200 of size 2048 next 67\n",
      "2023-05-20 18:03:18.855034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e009a00 of size 1024 next 72\n",
      "2023-05-20 18:03:18.855039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e009e00 of size 1024 next 70\n",
      "2023-05-20 18:03:18.855043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00a200 of size 1024 next 71\n",
      "2023-05-20 18:03:18.855047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00a600 of size 1024 next 74\n",
      "2023-05-20 18:03:18.855052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00aa00 of size 1024 next 75\n",
      "2023-05-20 18:03:18.855056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00ae00 of size 256 next 78\n",
      "2023-05-20 18:03:18.855062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00af00 of size 256 next 79\n",
      "2023-05-20 18:03:18.855066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00b000 of size 256 next 80\n",
      "2023-05-20 18:03:18.855070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00b100 of size 256 next 83\n",
      "2023-05-20 18:03:18.855075: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00b200 of size 256 next 87\n",
      "2023-05-20 18:03:18.855079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00b300 of size 256 next 88\n",
      "2023-05-20 18:03:18.855083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00b400 of size 256 next 89\n",
      "2023-05-20 18:03:18.855088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00b500 of size 256 next 90\n",
      "2023-05-20 18:03:18.855092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00b600 of size 256 next 91\n",
      "2023-05-20 18:03:18.855096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00b700 of size 256 next 81\n",
      "2023-05-20 18:03:18.855101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00b800 of size 1024 next 82\n",
      "2023-05-20 18:03:18.855105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00bc00 of size 256 next 92\n",
      "2023-05-20 18:03:18.855109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00bd00 of size 256 next 93\n",
      "2023-05-20 18:03:18.855114: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00be00 of size 256 next 94\n",
      "2023-05-20 18:03:18.855118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00bf00 of size 256 next 95\n",
      "2023-05-20 18:03:18.855122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00c000 of size 256 next 96\n",
      "2023-05-20 18:03:18.855127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00c100 of size 256 next 97\n",
      "2023-05-20 18:03:18.855131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00c200 of size 256 next 98\n",
      "2023-05-20 18:03:18.855135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00c300 of size 768 next 99\n",
      "2023-05-20 18:03:18.855140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00c600 of size 768 next 100\n",
      "2023-05-20 18:03:18.855144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00c900 of size 256 next 101\n",
      "2023-05-20 18:03:18.855148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00ca00 of size 256 next 102\n",
      "2023-05-20 18:03:18.855153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00cb00 of size 256 next 103\n",
      "2023-05-20 18:03:18.855157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00cc00 of size 256 next 104\n",
      "2023-05-20 18:03:18.855161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00cd00 of size 256 next 105\n",
      "2023-05-20 18:03:18.855166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00ce00 of size 256 next 106\n",
      "2023-05-20 18:03:18.855170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00cf00 of size 2304 next 107\n",
      "2023-05-20 18:03:18.855174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00d800 of size 2304 next 108\n",
      "2023-05-20 18:03:18.855179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00e100 of size 256 next 109\n",
      "2023-05-20 18:03:18.855183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00e200 of size 256 next 110\n",
      "2023-05-20 18:03:18.855187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00e300 of size 256 next 111\n",
      "2023-05-20 18:03:18.855192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00e400 of size 256 next 112\n",
      "2023-05-20 18:03:18.855196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00e500 of size 256 next 113\n",
      "2023-05-20 18:03:18.855200: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00e600 of size 256 next 114\n",
      "2023-05-20 18:03:18.855206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00e700 of size 512 next 117\n",
      "2023-05-20 18:03:18.855210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00e900 of size 512 next 118\n",
      "2023-05-20 18:03:18.855215: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00eb00 of size 512 next 119\n",
      "2023-05-20 18:03:18.855219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00ed00 of size 512 next 120\n",
      "2023-05-20 18:03:18.855223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00ef00 of size 512 next 121\n",
      "2023-05-20 18:03:18.855228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00f100 of size 512 next 122\n",
      "2023-05-20 18:03:18.855232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e00f300 of size 4608 next 123\n",
      "2023-05-20 18:03:18.855237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e010500 of size 4608 next 124\n",
      "2023-05-20 18:03:18.855241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e011700 of size 512 next 125\n",
      "2023-05-20 18:03:18.855245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e011900 of size 512 next 126\n",
      "2023-05-20 18:03:18.855249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e011b00 of size 512 next 127\n",
      "2023-05-20 18:03:18.855254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e011d00 of size 512 next 128\n",
      "2023-05-20 18:03:18.855258: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e011f00 of size 512 next 129\n",
      "2023-05-20 18:03:18.855262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e012100 of size 512 next 130\n",
      "2023-05-20 18:03:18.855267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e012300 of size 1024 next 132\n",
      "2023-05-20 18:03:18.855271: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e012700 of size 1024 next 133\n",
      "2023-05-20 18:03:18.855276: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e012b00 of size 1024 next 134\n",
      "2023-05-20 18:03:18.855280: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e012f00 of size 1024 next 135\n",
      "2023-05-20 18:03:18.855284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e013300 of size 1024 next 136\n",
      "2023-05-20 18:03:18.855289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e013700 of size 1024 next 37\n",
      "2023-05-20 18:03:18.855293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e013b00 of size 32768 next 36\n",
      "2023-05-20 18:03:18.855298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e01bb00 of size 32768 next 115\n",
      "2023-05-20 18:03:18.855302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e023b00 of size 32768 next 116\n",
      "2023-05-20 18:03:18.855307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e02bb00 of size 196608 next 54\n",
      "2023-05-20 18:03:18.855313: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e05bb00 of size 131072 next 53\n",
      "2023-05-20 18:03:18.855317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e07bb00 of size 360192 next 86\n",
      "2023-05-20 18:03:18.855322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e0d3a00 of size 131072 next 131\n",
      "2023-05-20 18:03:18.855326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e0f3a00 of size 2048 next 139\n",
      "2023-05-20 18:03:18.855331: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e0f4200 of size 2048 next 140\n",
      "2023-05-20 18:03:18.855335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e0f4a00 of size 2048 next 141\n",
      "2023-05-20 18:03:18.855339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e0f5200 of size 2048 next 142\n",
      "2023-05-20 18:03:18.855344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e0f5a00 of size 2048 next 143\n",
      "2023-05-20 18:03:18.855348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e0f6200 of size 2048 next 144\n",
      "2023-05-20 18:03:18.855354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e0f6a00 of size 545024 next 73\n",
      "2023-05-20 18:03:18.855358: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7eea5e17bb00 of size 541952 next 18446744073709551615\n",
      "2023-05-20 18:03:18.855363: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-05-20 18:03:18.855371: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 114 Chunks of size 256 totalling 28.5KiB\n",
      "2023-05-20 18:03:18.855377: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 22 Chunks of size 512 totalling 11.0KiB\n",
      "2023-05-20 18:03:18.855382: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 768 totalling 2.2KiB\n",
      "2023-05-20 18:03:18.855387: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 26 Chunks of size 1024 totalling 26.0KiB\n",
      "2023-05-20 18:03:18.855393: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-05-20 18:03:18.855398: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 2048 totalling 24.0KiB\n",
      "2023-05-20 18:03:18.855403: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 2304 totalling 6.8KiB\n",
      "2023-05-20 18:03:18.855408: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 4608 totalling 13.5KiB\n",
      "2023-05-20 18:03:18.855414: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14080 totalling 13.8KiB\n",
      "2023-05-20 18:03:18.855419: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 32768 totalling 96.0KiB\n",
      "2023-05-20 18:03:18.855425: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 131072 totalling 256.0KiB\n",
      "2023-05-20 18:03:18.855430: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 196608 totalling 192.0KiB\n",
      "2023-05-20 18:03:18.855436: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 360192 totalling 351.8KiB\n",
      "2023-05-20 18:03:18.855441: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 524288 totalling 512.0KiB\n",
      "2023-05-20 18:03:18.855447: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 541952 totalling 529.2KiB\n",
      "2023-05-20 18:03:18.855453: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 545024 totalling 532.2KiB\n",
      "2023-05-20 18:03:18.855458: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3360000 totalling 3.20MiB\n",
      "2023-05-20 18:03:18.855464: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 327680000 totalling 937.50MiB\n",
      "2023-05-20 18:03:18.855469: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 840000000 totalling 801.09MiB\n",
      "2023-05-20 18:03:18.855475: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 21600000000 totalling 20.12GiB\n",
      "2023-05-20 18:03:18.855480: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 21.82GiB\n",
      "2023-05-20 18:03:18.855486: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 36509319168 memory_limit_: 48938811392 available bytes: 12429492224 curr_region_allocation_bytes_: 34359738368\n",
      "2023-05-20 18:03:18.855497: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                     48938811392\n",
      "InUse:                     23429058560\n",
      "MaxInUse:                  24451425536\n",
      "NumAllocs:                     1131733\n",
      "MaxAllocSize:              21600000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-05-20 18:03:18.855516: W tensorflow/tsl/framework/bfc_allocator.cc:497] **************************************************************________________________________**_***\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train the model with your data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), \n\u001b[1;32m      3\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[checkpoint_cb, early_stopping_cb])\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Train the model with your data\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                    epochs=epochs, batch_size=batch_size, verbose=1,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('best_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save, Load, and Display Model History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model attributes\n",
    "timestamp = int(time.time())\n",
    "file_name = '../04_Age_Prediction/model_history.csv'\n",
    "description = f\"{timestamp}\"\n",
    "input_shape = str(X_train.shape[1:])\n",
    "num_params = model.count_params()\n",
    "epochs = len(history.history['loss'])\n",
    "optimizer = optimizer\n",
    "loss_function = loss\n",
    "train_mae = min(history.history['mae'])\n",
    "validation_mae = min(history.history['val_mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at ../04_Age_Prediction/08_models/1684584841.h5\n"
     ]
    }
   ],
   "source": [
    "def append_model_history_to_file(file_name, description, input_shape, num_params, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae):\n",
    "    train_mae = round(train_mae, 6)\n",
    "    validation_mae = round(validation_mae, 6)\n",
    "\n",
    "    if not os.path.exists(file_name):\n",
    "        with open(file_name, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(['Model', 'Input Shape', 'Model Params', 'Epochs', 'Batch Size', 'Optimizer', 'Loss Function', 'Train MAE', 'Validation MAE'])\n",
    "\n",
    "    with open(file_name, 'r', newline='') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        try:\n",
    "            next(csv_reader)  # Skip the header row\n",
    "        except StopIteration:\n",
    "            pass  # The CSV file is empty or only contains the header row\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if list(map(str, row[1:])) == list(map(str, [input_shape, num_params, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae])):\n",
    "                print(\"Entry with the same parameters already exists.\")\n",
    "                return False\n",
    "\n",
    "    with open(file_name, 'a', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow([description, input_shape, num_params, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae])\n",
    "\n",
    "    return True\n",
    "\n",
    "new_entry_added = append_model_history_to_file(file_name, description, input_shape, num_params, epochs, batch_size, optimizer, loss_function, train_mae, validation_mae)\n",
    "\n",
    "# Save model\n",
    "def save_model_architecture(model, file_name):\n",
    "    model_json = model.to_json()\n",
    "    with open(file_name, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "if new_entry_added:\n",
    "    model_file = f\"../04_Age_Prediction/08_models/{description}.h5\"\n",
    "    model.save(model_file)\n",
    "    print(f\"Model saved at {model_file}\")\n",
    "else:\n",
    "    print(\"Model not saved as an entry with the same parameters already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Input Shape</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Loss Function</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Validation MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1684111562</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>8770497</td>\n",
       "      <td>155</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>12.435976</td>\n",
       "      <td>8.629502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1684118998</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>33625217</td>\n",
       "      <td>132</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>10.202019</td>\n",
       "      <td>6.590096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1684126499</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>18144705</td>\n",
       "      <td>170</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>9.910834</td>\n",
       "      <td>6.491637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1684130813</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>9872321</td>\n",
       "      <td>213</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>10.675910</td>\n",
       "      <td>7.109921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1684133411</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>10344897</td>\n",
       "      <td>168</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>10.852635</td>\n",
       "      <td>7.511125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1684148562</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>77897345</td>\n",
       "      <td>212</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>10.725429</td>\n",
       "      <td>7.512293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1684208696</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>82101291</td>\n",
       "      <td>312</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>9.901710</td>\n",
       "      <td>7.452464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1684212422</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>11331745</td>\n",
       "      <td>108</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>10.285194</td>\n",
       "      <td>7.056834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1684219988</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>18217393</td>\n",
       "      <td>219</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1.237246</td>\n",
       "      <td>5.716532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1684300148</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>8770497</td>\n",
       "      <td>152</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>10.255740</td>\n",
       "      <td>6.360036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1684320186</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>33625217</td>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>8.891773</td>\n",
       "      <td>6.597941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1684394481</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>18144705</td>\n",
       "      <td>81</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>7.961771</td>\n",
       "      <td>5.572220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1684407927</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>18217393</td>\n",
       "      <td>79</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>2.391651</td>\n",
       "      <td>5.277592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1684485106</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>9872321</td>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>9.606898</td>\n",
       "      <td>6.405786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1684498043</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>10344897</td>\n",
       "      <td>157</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>9.617646</td>\n",
       "      <td>6.659074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1684584841</td>\n",
       "      <td>(200, 200, 3)</td>\n",
       "      <td>77897345</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>9.968779</td>\n",
       "      <td>7.026824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model    Input Shape  Model Params  Epochs  Batch Size Optimizer  \\\n",
       "0   1684111562  (200, 200, 3)       8770497     155          32      adam   \n",
       "1   1684118998  (200, 200, 3)      33625217     132          32      adam   \n",
       "2   1684126499  (200, 200, 3)      18144705     170          32      adam   \n",
       "3   1684130813  (200, 200, 3)       9872321     213          32      adam   \n",
       "4   1684133411  (200, 200, 3)      10344897     168          32      adam   \n",
       "5   1684148562  (200, 200, 3)      77897345     212          32      adam   \n",
       "6   1684208696  (200, 200, 3)      82101291     312          32      adam   \n",
       "7   1684212422  (200, 200, 3)      11331745     108          32      adam   \n",
       "8   1684219988  (200, 200, 3)      18217393     219          32      adam   \n",
       "9   1684300148  (200, 200, 3)       8770497     152          32      adam   \n",
       "10  1684320186  (200, 200, 3)      33625217      75          32      adam   \n",
       "11  1684394481  (200, 200, 3)      18144705      81          32      adam   \n",
       "12  1684407927  (200, 200, 3)      18217393      79          32      adam   \n",
       "13  1684485106  (200, 200, 3)       9872321     123          32      adam   \n",
       "14  1684498043  (200, 200, 3)      10344897     157          32      adam   \n",
       "15  1684584841  (200, 200, 3)      77897345      63          32      adam   \n",
       "\n",
       "         Loss Function  Train MAE  Validation MAE  \n",
       "0   mean_squared_error  12.435976        8.629502  \n",
       "1   mean_squared_error  10.202019        6.590096  \n",
       "2   mean_squared_error   9.910834        6.491637  \n",
       "3   mean_squared_error  10.675910        7.109921  \n",
       "4   mean_squared_error  10.852635        7.511125  \n",
       "5   mean_squared_error  10.725429        7.512293  \n",
       "6   mean_squared_error   9.901710        7.452464  \n",
       "7   mean_squared_error  10.285194        7.056834  \n",
       "8   mean_squared_error   1.237246        5.716532  \n",
       "9   mean_squared_error  10.255740        6.360036  \n",
       "10  mean_squared_error   8.891773        6.597941  \n",
       "11  mean_squared_error   7.961771        5.572220  \n",
       "12  mean_squared_error   2.391651        5.277592  \n",
       "13  mean_squared_error   9.606898        6.405786  \n",
       "14  mean_squared_error   9.617646        6.659074  \n",
       "15  mean_squared_error   9.968779        7.026824  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_to_dataframe(file_name):\n",
    "    if not os.path.exists(file_name):\n",
    "        print(\"File does not exist.\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(file_name)\n",
    "    return df\n",
    "\n",
    "file_name = '../04_Age_Prediction/model_history.csv'\n",
    "df = load_data_to_dataframe(file_name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify model to load\n",
    "# model_to_load = \"1683270923\"\n",
    "\n",
    "# def load_and_display_model_architecture(file_name):\n",
    "#     if not os.path.exists(file_name):\n",
    "#         print(\"File does not exist.\")\n",
    "#         return None\n",
    "\n",
    "#     with open(file_name, \"r\") as json_file:\n",
    "#         model_json = json_file.read()\n",
    "    \n",
    "#     model = model_from_json(model_json)\n",
    "#     model.summary()\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model_architecture_file = f\"../04_Age_Prediction/models/{model_to_load}.json\"\n",
    "# model = load_and_display_model_architecture(model_architecture_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
